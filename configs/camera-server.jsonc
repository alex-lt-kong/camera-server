{
	"httpService": {
		"interface": "127.0.0.1",
		"port": 54321,
		"ssl": {
			"enabled": false,
			"keyPath": "",
			"crtPath": ""
		},
		"httpAuthentication": {
			"enabled": false,
			"accounts": {
				"defaultUser": "defaultPassword"
			}
		}
	},
	"devicesDefault": {
		"name": "Device-{{deviceIndex}}",
		"uri": "/dev/video{{deviceIndex}}",
		"frame": {
			/* Setting this to a lower value to limit CPU usage. For example,
			if the program can read 60 frames per sec from a deivce and
			throttleFpsIfHigherThan is set to 10, the program roughly discards
			5 in every 6 frames. Discarded frames are neither decompressed nor
			decoded, saving a lot of CPU resource. */
			"throttleFpsIfHigherThan": 29.9,
			"rotation": -1,
			"textOverlay": {
				/* By default, Camera Server writes some basic information, such as
				timestamp and device name, to each frame. Disable it if it is
				undesired. */
				"enabled": true,
				"fontScale": 1.0
			},
			/* The below preferred values are directly sent to OpenCV. OpenCV (and
			its back-end) may or may not honor our request. Note that:
			1. If OpenCV (or underlying video devices) don't honor our preference,
			to avoid causing performance issue, Camera Server will not resize the
			frame based on them;
			2.  these parameters do not control how videos are recorded, video
			recording are controlled by the motionDetection.videoRecording section
			below. */
			"preferredWidth": -1,
			"preferredHeight": -1,
			"preferredFps": 30
		},
		/* Apart from motion detection and video recording, Camera server
		supports another important feature: It provides downsteam data 
		uses (i.e., another program) with encoded JPEG image on a regular
		basis. This function is called "snapshot". Camera server supports
		a few common IPC method to share the JPEG image to other programs.*/
		"snapshot": {
			/* frameInterval is effective after frame.throttleFpsIfHigherThan is
			applied. For example, if throttleFpsIfHigherThan is set to 30, and
			frameInterval is set to 5, then the snapshot will be generated
			every 150 frames read from the source device. */
			"frameInterval": 5,
			"ipc": {
				"switch": {
					"http": true,
					"file": true
				},
				"file": {
					"path": "/tmp/snapshot-{{timestamp}}.jpg"
				},
				"http": {
					/* The path of HTTP request is not configurable, to access a
					device, users should always use:
					http(s)://interface:port/live_image/deviceId={{deviceIndex}} 
					where interface, port, etc are configured in the httpService
					section.*/
				}
			}
		},
		"motionDetection": {
			/* Valid values are:
			* 0, meaning "disabled": motion detection will NOT run and no video
			will be saved.
			* 1, meaning "detectMotion": motion detection will run and video will
			only be recorded if the following conditions are met. Events will be
			triggered.
			* 2, meaning "alwaysRecord": motion detection will NOT run and video
			will always be recorded. Events will be triggered.
			*/
			"mode": 0,
			/* To conserve CPU resources, motion detection will only be
			performed on every Nth frame, instead of every frame. */
			"diffEveryNthFrame": 10,
			/* If the b/w value of the same pixel is changed by more than
			pixelDiffAbsThreshold, this pixel will be considered "changed"*/
			"pixelDiffAbsThreshold": 32,
			/* If the number of changed pixel divided by the total number
			of pixels are within the range of [frameDiffPercentageLowerLimit,
			frameDiffPercentageUpperLimit], the frame will be considered
			"changed". A changed frame will trigger motion detection. */
			"frameDiffPercentageLowerLimit": 1.0,
			"frameDiffPercentageUpperLimit": 50.0,
			// Useful for debug but CPU intensive
			"drawContours": false,
			"videoRecording": {
				/* If a motion is detected on the N-th frame, the video shall start from
				(N - precaptureFrames)-th frame, so that we can get a bit of context
				about the motion being recorded */
				"precaptureFrames": 5,
				"minFramesPerVideo": 240,
				"maxFramesPerVideo": 108000,
				"encoder": {
					"useExternal": false,
					"internal": {
						"width": 1920,
						"height": 1080,
						"fps": 30,
						"videoPath": "/tmp/{{timestampOnVideoStarts}}.mp4"
					},
					"external": {
						"pipeRawVideoTo": "/usr/bin/ffmpeg -y -f rawvideo -pixel_format bgr24 -framerate 30 -video_size 1920x1080 -i pipe:0 -vcodec libx264 -pix_fmt yuv420p /tmp/{{timestamp}}.mp4 >> /tmp/ffmpeg-vid1.log 2>&1"
					}
				}
			}
		},
		"events": {
			"onVideoStarts": ["/usr/bin/printf", "video starts at [{{timestampOnVideoStarts}}] %s", "!"],
			"onVideoEnds": ["/usr/bin/echo", "onVideoEnds echoed from device [{{deviceIndex}}]"],
			"onDeviceOffline": ["/usr/bin/echo", "Device [{{deviceIndex}}] is offline at [{{timestampOnDeviceOffline}}]"],
			"onDeviceBackOnline": ["/usr/bin/echo", "Device [{{deviceName}}] is back online"]
		}
		
	},
	"devices": [
		/* A pair of braces ({}) means we have one device, but we want
		to leave all the settings to default. */
		{} 
	]
}
